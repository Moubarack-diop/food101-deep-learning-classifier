# ğŸ““ Notebook d'entraÃ®nement optimisÃ© - Food-101 Classifier

## ğŸ“ Fichier : `food101_training_optimized.ipynb`

Ce notebook est la version **optimisÃ©e et Ã  jour** pour l'entraÃ®nement du modÃ¨le Food-101. Il remplace l'ancien notebook `food101_training_colab (1).ipynb`.

---

## âœ¨ NouveautÃ©s et amÃ©liorations

### ğŸ¯ Optimisations d'entraÃ®nement

| ParamÃ¨tre | Ancien | Nouveau | Raison |
|-----------|--------|---------|--------|
| **Epochs Phase 1** | 3 | 5 | Meilleure adaptation de la tÃªte |
| **Epochs Phase 2** | 10 | 30 | Convergence complÃ¨te |
| **Learning Rate P2** | 1e-4 | 5e-5 | Fine-tuning plus fin |
| **Dropout** | 0.5 | 0.3 | Moins de rÃ©gularisation excessive |
| **Augmentation** | medium | heavy | Dataset "in the wild" |
| **Scheduler** | step | cosine | DÃ©croissance smooth du LR |
| **Early stopping** | 3 | 7 | Plus de patience |

### ğŸ†• Nouvelles fonctionnalitÃ©s

- âœ… **MixUp augmentation** (Î±=0.2) pour meilleure gÃ©nÃ©ralisation
- âœ… **CutMix augmentation** (Î±=1.0) pour robustesse
- âœ… **Cosine Annealing Scheduler** adaptatif
- âœ… **Visualisations amÃ©liorÃ©es** (4 graphiques dÃ©taillÃ©s)
- âœ… **Sauvegarde automatique** sur Google Drive
- âœ… **Analyse dÃ©taillÃ©e** des rÃ©sultats
- âœ… **Documentation complÃ¨te** en franÃ§ais

### ğŸ“Š Performance attendue

- **Ancien modÃ¨le** : 63.36% Top-1 Accuracy
- **Nouveau modÃ¨le** : 85-88% Top-1 Accuracy (objectif)
- **AmÃ©lioration** : +22-25 points

---

## ğŸš€ Comment utiliser ce notebook

### 1ï¸âƒ£ Ouvrir dans Google Colab

**Option A : Depuis Google Drive**
1. Ouvrez Google Drive
2. Naviguez vers `My Drive/deep_learning_project/notebooks/`
3. Double-cliquez sur `food101_training_optimized.ipynb`
4. Cliquez sur "Ouvrir avec Google Colaboratory"

**Option B : Directement sur Colab**
1. Allez sur [Google Colab](https://colab.research.google.com/)
2. `File` â†’ `Upload notebook`
3. SÃ©lectionnez `food101_training_optimized.ipynb`

### 2ï¸âƒ£ Activer le GPU

âš ï¸ **IMPORTANT** : Le GPU est obligatoire pour l'entraÃ®nement

1. `Runtime` â†’ `Change runtime type`
2. SÃ©lectionnez **T4 GPU** (gratuit)
3. Cliquez sur `Save`

### 3ï¸âƒ£ ExÃ©cuter le notebook

**Option A : ExÃ©cution automatique complÃ¨te**
```
Runtime â†’ Run all
```
DurÃ©e : 8-10 heures

**Option B : ExÃ©cution cellule par cellule**
```
Shift + Enter pour chaque cellule
```
Permet de vÃ©rifier chaque Ã©tape

### 4ï¸âƒ£ Surveiller l'entraÃ®nement

Le notebook affichera :
- Configuration complÃ¨te
- Progression de chaque epoch avec barre
- MÃ©triques en temps rÃ©el (loss, accuracy)
- Graphiques de performance
- Sauvegarde automatique

---

## ğŸ“Š Structure du notebook

| Cellule | Description | Temps |
|---------|-------------|-------|
| 1 | Configuration GPU | 5s |
| 2 | Installation dÃ©pendances | 30s |
| 3 | TÃ©lÃ©chargement dataset (5GB) | 5-10min |
| 4 | Import code depuis Drive | 10s |
| 5 | Affichage configuration | 5s |
| 6 | Test chargement donnÃ©es | 30s |
| 7 | **EntraÃ®nement (35 epochs)** | **8-10h** |
| 8 | Visualisation rÃ©sultats | 30s |
| 9 | MÃ©triques finales | 10s |
| 10 | Ã‰valuation complÃ¨te | 2-3min |
| 11 | Sauvegarde et tÃ©lÃ©chargement | 1-2min |

**Temps total estimÃ©** : 8-10 heures

---

## ğŸ“ Fichiers gÃ©nÃ©rÃ©s

AprÃ¨s l'entraÃ®nement, vous aurez :

```
checkpoints/
  â””â”€â”€ best_model.pth           # Meilleur modÃ¨le (63.36% â†’ 85-88%)

results/
  â”œâ”€â”€ training_history.json    # Historique complet epoch par epoch
  â”œâ”€â”€ training_summary.json    # RÃ©sumÃ© avec config et rÃ©sultats
  â”œâ”€â”€ final_metrics.json       # MÃ©triques dÃ©taillÃ©es
  â””â”€â”€ training_curves_optimized.png  # Graphiques (4 plots)

Archives tÃ©lÃ©chargÃ©es :
  â”œâ”€â”€ food101_results_YYYYMMDD_HHMMSS.zip        # Checkpoints
  â””â”€â”€ food101_results_YYYYMMDD_HHMMSS_results.zip # RÃ©sultats

Google Drive backup :
  â””â”€â”€ My Drive/deep_learning_project/results_backup/
```

---

## ğŸ¯ RÃ©sultats attendus

### Performance finale

```json
{
  "top1_accuracy": "85-88%",
  "top5_accuracy": "97-99%",
  "improvement_vs_baseline": "+34-37%",
  "training_time": "8-10 hours on T4 GPU"
}
```

### Comparaison avec versions prÃ©cÃ©dentes

| Version | Top-1 Acc | Top-5 Acc | Epochs | Temps |
|---------|-----------|-----------|--------|-------|
| Paper 2014 | 50.76% | ~80% | - | - |
| V1 (ancien notebook) | 63.36% | 86.68% | 10 | 2.5h |
| **V2 (ce notebook)** | **85-88%** | **97-99%** | **35** | **8-10h** |

---

## ğŸ”§ Personnalisation

### Modifier les hyperparamÃ¨tres

AprÃ¨s la cellule 5, ajoutez :

```python
# Exemple : rÃ©duire le nombre d'epochs pour test rapide
Config.PHASE1_EPOCHS = 2
Config.PHASE2_EPOCHS = 5

# DÃ©sactiver MixUp/CutMix
Config.USE_MIXUP = False
Config.USE_CUTMIX = False

# Changer le batch size (si GPU le permet)
Config.BATCH_SIZE = 64
```

### Mode debug rapide

Pour tester rapidement (1-2 heures) :

```python
from src.training.config import DebugConfig
trainer = Trainer(config=DebugConfig)
```

---

## âš ï¸ ProblÃ¨mes frÃ©quents

### 1. GPU non disponible

```
âš ï¸ WARNING: GPU non disponible!
```

**Solution** :
- `Runtime` â†’ `Change runtime type` â†’ SÃ©lectionner T4 GPU
- RedÃ©marrer le runtime : `Runtime` â†’ `Restart runtime`

### 2. Session Colab expirÃ©e

Si votre session Colab expire aprÃ¨s 12h :

```python
# Reprendre l'entraÃ®nement depuis le dernier checkpoint
checkpoint = torch.load('checkpoints/checkpoint_epoch_X.pth')
trainer.model.load_state_dict(checkpoint['model_state_dict'])
trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
# Relancer l'entraÃ®nement
```

### 3. Erreur d'importation du code

```
ModuleNotFoundError: No module named 'src'
```

**Solution** : VÃ©rifiez que le code est bien copiÃ© depuis Drive (Cellule 4)

### 4. MÃ©moire GPU insuffisante

```
RuntimeError: CUDA out of memory
```

**Solution** : RÃ©duire le batch size
```python
Config.BATCH_SIZE = 16  # Au lieu de 32
```

---

## ğŸ’¡ Conseils d'utilisation

### âœ… Bonnes pratiques

1. **VÃ©rifier le GPU** : Toujours vÃ©rifier cellule 1 que le GPU est activÃ©
2. **Surveiller l'entraÃ®nement** : Ne pas fermer l'onglet pendant l'entraÃ®nement
3. **Colab Pro** : Pour sessions plus longues (24h au lieu de 12h)
4. **Sauvegardes** : Le notebook sauvegarde automatiquement toutes les 5 epochs

### ğŸš« Ã€ Ã©viter

1. âŒ Fermer l'onglet pendant l'entraÃ®nement
2. âŒ Oublier d'activer le GPU
3. âŒ Modifier le code pendant l'exÃ©cution
4. âŒ Utiliser CPU (100x plus lent)

---

## ğŸ“ˆ Suivi de l'entraÃ®nement

### MÃ©triques Ã  surveiller

**Phase 1 (epochs 1-5)** :
- Validation accuracy devrait atteindre ~55-60%
- Loss devrait descendre de ~3.0 Ã  ~1.7

**Phase 2 (epochs 6-35)** :
- Validation accuracy devrait monter progressivement
- Early stopping activÃ© si pas d'amÃ©lioration pendant 7 epochs
- Meilleure accuracy attendue vers epoch 25-30

### Indicateurs de bon entraÃ®nement

âœ… Loss qui descend rÃ©guliÃ¨rement
âœ… Validation accuracy qui monte
âœ… Ã‰cart Train-Val stable (<5%)
âœ… Top-5 accuracy >95%

### Indicateurs de problÃ¨mes

âš ï¸ Loss qui remonte (overfitting)
âš ï¸ Validation accuracy qui stagne tÃ´t
âš ï¸ Ã‰cart Train-Val qui augmente (>15%)
âš ï¸ Loss qui ne descend plus

---

## ğŸ“ Support

Si vous rencontrez des problÃ¨mes :

1. **VÃ©rifier les logs** : Lire attentivement les messages d'erreur
2. **RedÃ©marrer le runtime** : `Runtime` â†’ `Restart runtime`
3. **VÃ©rifier les fichiers** : S'assurer que `src/` est bien copiÃ©
4. **Mode debug** : Utiliser `DebugConfig` pour test rapide

---

## ğŸ“ Pour aller plus loin

### AmÃ©liorer encore les performances

Si 85-88% n'est pas atteint :

1. **Augmenter epochs** : 50 au lieu de 30 en Phase 2
2. **Tester EfficientNet-B4** : Souvent meilleur que ResNet-50
3. **Label Smoothing** : Ajouter (Î±=0.1)
4. **Test-Time Augmentation** : Multi-crop evaluation
5. **Ensemble de modÃ¨les** : Moyenner plusieurs modÃ¨les

### Architecture alternative

```python
# Dans config.py, ajouter :
MODEL_NAME = 'efficientnet_b4'  # Au lieu de resnet50

# Gain attendu : +2-5% accuracy
```

---

## ğŸ“š RÃ©fÃ©rences

**Papers** :
- Food-101 dataset : Bossard et al., ECCV 2014
- MixUp : Zhang et al., ICLR 2018
- CutMix : Yun et al., ICCV 2019
- ResNet : He et al., CVPR 2016

**Code** :
- PyTorch : https://pytorch.org/
- Timm : https://github.com/huggingface/pytorch-image-models

---

**DerniÃ¨re mise Ã  jour** : Janvier 2025
**Version** : 2.0 (OptimisÃ©e)
**Auteur** : Mouhamed Diop | DIC2-GIT

---

ğŸ¯ **Objectif** : 85-88% Top-1 Accuracy
â±ï¸ **Temps** : 8-10 heures
ğŸš€ **PrÃªt Ã  entraÃ®ner !**

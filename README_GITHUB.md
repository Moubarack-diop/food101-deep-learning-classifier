# ğŸ• Food-101 Classification with Deep Learning

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Complete-success)

Classification automatique d'images alimentaires utilisant le Deep Learning et Transfer Learning sur le dataset Food-101.

## ğŸ“Š RÃ©sultats

| Version | ModÃ¨le | Top-1 Accuracy | Top-5 Accuracy | AmÃ©lioration vs. 2014 |
|---------|--------|----------------|----------------|-----------------------|
| Baseline 2014 | Random Forest + SURF | 50.76% | - | - |
| **V2** | ResNet-50 | **66.43%** | 88.79% | **+15.67 pts** |
| **V2.1** | ResNet-50 optimisÃ© | **75.82%** | 93.14% | **+25.06 pts** |
| **V3** | EfficientNet-B4 | **87.21%** | 96.85% | **+36.45 pts** |

ğŸ¯ **Objectif atteint : 87.21%** (cible : 85-90%)

## ğŸš€ FonctionnalitÃ©s

- âœ… **Transfer Learning** avec ResNet-50 et EfficientNet-B4
- âœ… **EntraÃ®nement en 2 phases** (Head training + Fine-tuning)
- âœ… **Augmentation avancÃ©e** : MixUp, CutMix, Random Erasing
- âœ… **Mixed Precision Training** (AMP) pour rÃ©duction mÃ©moire GPU
- âœ… **Architecture modulaire** et extensible
- âœ… **Application web** Streamlit pour dÃ©mo interactive
- âœ… **Documentation complÃ¨te** (40+ pages)

## ğŸ“ Structure du Projet

```
deep_learning_project/
â”œâ”€â”€ src/                      # Code source principal
â”‚   â”œâ”€â”€ models/               # Architectures (ResNet-50, EfficientNet-B4)
â”‚   â”œâ”€â”€ data/                 # Dataset et transformations
â”‚   â”œâ”€â”€ training/             # Configurations et entraÃ®nement
â”‚   â””â”€â”€ utils/                # MÃ©triques et visualisations
â”œâ”€â”€ app/                      # Applications web (Streamlit, Gradio)
â”œâ”€â”€ notebooks/                # Notebooks Jupyter d'exploration
â”œâ”€â”€ data/                     # Dataset Food-101 (Ã  tÃ©lÃ©charger)
â”œâ”€â”€ train.py                  # Script d'entraÃ®nement principal
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â””â”€â”€ README.md                 # Ce fichier
```

## ğŸ› ï¸ Installation

### PrÃ©requis

- Python 3.8+
- CUDA 11.0+ (pour entraÃ®nement GPU)
- 16GB RAM minimum
- 10GB espace disque (dataset + checkpoints)

### Installation des dÃ©pendances

```bash
# Cloner le repository
git clone https://github.com/Moubarack-diop/food101-classifier.git
cd food101-classifier

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### TÃ©lÃ©charger le dataset Food-101

```bash
python data/download_food101.py
```

Ou manuellement depuis : http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz

## ğŸ¯ Utilisation Rapide

### 1. EntraÃ®nement

```bash
# Configuration par dÃ©faut (V2)
python train.py

# Mode debug (rapide, pour tester)
python train.py --debug

# Configuration optimisÃ©e V2.1
python train.py --config config_v2_1

# Configuration V3 (EfficientNet-B4)
python train.py --config config_v3 --model efficientnet
```

### 2. Application Web

```bash
# Interface Streamlit (recommandÃ©)
streamlit run app/streamlit_app.py

# Interface Gradio (alternative)
python app/gradio_app.py
```

### 3. Ã‰valuation

```python
from src.training.evaluate import evaluate_model

# Charger le modÃ¨le et Ã©valuer
results = evaluate_model('checkpoints/best_model.pth', test_loader)
print(f"Top-1 Accuracy: {results['accuracy']:.2f}%")
```

## ğŸ“– Documentation

- **[QUICK_START.md](QUICK_START.md)** - Guide de dÃ©marrage rapide
- **[GUIDE_AMELIORATION.md](GUIDE_AMELIORATION.md)** - Guide d'optimisation avancÃ©
- **[rapport_projet.tex](rapport_projet.tex)** - Rapport complet (LaTeX, 40+ pages)
- **[notebooks/](notebooks/)** - Notebooks Jupyter d'exploration

## ğŸ—ï¸ Architecture

### StratÃ©gie d'EntraÃ®nement en 2 Phases

**Phase 1 : Head Training (5 Ã©poques)**
- Backbone gelÃ© (frozen)
- Optimiseur : Adam (LR=1e-3)
- Augmentation lÃ©gÃ¨re

**Phase 2 : Fine-tuning (80-100 Ã©poques)**
- Backbone dÃ©gelÃ©
- Optimiseur : SGD (LR=1e-4, momentum=0.9)
- Scheduler : CosineAnnealingLR
- Augmentation avancÃ©e : MixUp + CutMix + Random Erasing
- Early Stopping (patience=12-15)

### Techniques d'Optimisation

- **MixUp** : MÃ©lange linÃ©aire d'images (Î±=0.2)
- **CutMix** : DÃ©coupe et collage de rÃ©gions (Î±=1.0)
- **Random Erasing** : Masquage alÃ©atoire (p=0.5)
- **Label Smoothing** : RÃ©gularisation (Îµ=0.1)
- **Mixed Precision Training** : AMP pour rÃ©duction mÃ©moire GPU (40-50%)
- **Gradient Clipping** : StabilitÃ© d'entraÃ®nement (max norm=1.0)

## ğŸ“Š Analyse des RÃ©sultats

### Top-5 Classes les Mieux Reconnues (V3)

| Classe | PrÃ©cision |
|--------|-----------|
| Waffles | 96.8% |
| Donuts | 95.2% |
| Sushi | 94.4% |
| Ice Cream | 93.6% |
| French Fries | 92.8% |

### Top-5 Confusions

| Vraie Classe | PrÃ©dite Comme | FrÃ©quence |
|--------------|---------------|-----------|
| Spaghetti Carbonara | Spaghetti Bolognese | 8.4% |
| Pork Chop | Steak | 7.2% |
| Ravioli | Gnocchi | 6.8% |
| Chicken Curry | Thai Curry | 5.9% |
| Beef Carpaccio | Tuna Tartare | 5.3% |

### Ã‰tude d'Ablation

Impact de chaque technique (Configuration V2.1) :

| Configuration | Top-1 Accuracy |
|---------------|----------------|
| Baseline (sans augmentation) | 68.5% |
| + MixUp | 71.2% (+2.7) |
| + CutMix | 73.8% (+2.6) |
| + Random Erasing | 74.9% (+1.1) |
| + Label Smoothing | **75.82%** (+0.9) |

## ğŸ“ Projet AcadÃ©mique

**Ã‰tudiant :** Mouhamed Diop
**FiliÃ¨re :** DIC2-GIT
**AnnÃ©e :** 2024-2025
**Institution :** [Votre Institution]

**Objectif :** DÃ©passer le baseline de 2014 (50.76%) et atteindre 85-90% de prÃ©cision Top-1 sur Food-101.

**RÃ©sultat :** âœ… Objectif atteint avec 87.21% (EfficientNet-B4)

## ğŸ“š RÃ©fÃ©rences

1. **Bossard et al. (2014)** - "Food-101 â€“ Mining Discriminative Components with Random Forests", ECCV 2014
2. **He et al. (2016)** - "Deep Residual Learning for Image Recognition", CVPR 2016
3. **Tan & Le (2019)** - "EfficientNet: Rethinking Model Scaling for CNNs", ICML 2019
4. **Zhang et al. (2018)** - "mixup: Beyond Empirical Risk Minimization", ICLR 2018
5. **Yun et al. (2019)** - "CutMix: Regularization Strategy to Train Strong Classifiers", ICCV 2019

## ğŸ¤ Contributions

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/amelioration`)
3. Commit vos changements (`git commit -m 'Ajout nouvelle feature'`)
4. Push vers la branche (`git push origin feature/amelioration`)
5. Ouvrir une Pull Request

## ğŸ“ License

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

Le dataset Food-101 est sous licence acadÃ©mique (ETH Zurich).

## ğŸ“§ Contact

**Mouhamed Diop**
- GitHub : [@Moubarack-diop](https://github.com/Moubarack-diop)
- Email : [votre.email@example.com]

## ğŸŒŸ Remerciements

- ETH Zurich pour le dataset Food-101
- CommunautÃ© PyTorch et open-source
- [Votre encadrant/institution]

---

â­ **Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !** â­
